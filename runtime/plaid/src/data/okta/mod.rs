use crate::{data::DataGeneratorLog, executor::Message};
use crossbeam_channel::Sender;
use lru::LruCache;
use plaid_stl::messages::{Generator, LogSource, LogbacksAllowed};
use reqwest::Client;
use serde::Deserialize;
use serde_json::Value;
use std::{num::NonZeroUsize, time::Duration};
use time::{format_description::well_known::Rfc3339, OffsetDateTime};

use super::DataGenerator;

const OKTA_LOG_PUBLISHED_FIELD_KEY: &str = "published";
const OKTA_LOG_UUID_FIELD_KEY: &str = "uuid";

#[derive(Deserialize)]
pub struct OktaConfig {
    /// API token used to authenticate to Okta
    token: String,
    /// Domain that API calls will be sent to
    domain: String,
    /// Sets the number of results that are returned in the response
    /// If no value is provided here, we will default to 100.
    #[serde(deserialize_with = "parse_limit")]
    #[serde(default = "default_okta_limit")]
    limit: u16,
    /// Number of milliseconds to wait in between calls to the Okta API.
    /// Okta enforces a rate limit of 50 calls/sec for the `/logs` endpoint.
    #[serde(default = "default_sleep_milliseconds")]
    sleep_duration: u64,
    /// How we ask the Okta API to sort logs. This can be "ASCENDING" (from oldest to newest)
    /// or "DESCENDING" (from newest to oldest). If the value is missing, default to "ASCENDING".
    #[serde(default = "default_log_sorting")]
    log_sorting: String,
    /// The maximum number of logbacks that each rule will be allowed to trigger
    /// per message received. If this is set to Limited(0), no rule will be able to use the log
    /// back functionality from messages generated by this webhook. If this is set to Limited(1),
    /// then EACH RULE will be able to trigger one logback. If this is set to Unlimited, then
    /// each rule will be able to trigger as many logbacks as they want (and those triggered rules
    /// will be able to as well). If this is not set, it will default to Limited(0).
    #[serde(default)]
    pub logbacks_allowed: LogbacksAllowed,
    /// Canonicalization time, i.e., after how many seconds we can consider logs as "stable"
    #[serde(default = "default_canon_time")]
    canon_time: u64,
}

/// Custom parser for limit. Returns an error if a limit = 0 or limit > 1000 is given
fn parse_limit<'de, D>(deserializer: D) -> Result<u16, D::Error>
where
    D: serde::Deserializer<'de>,
{
    let limit = u16::deserialize(deserializer)?;

    match limit {
        1..=1000 => Ok(limit),
        0 => Err(serde::de::Error::custom(
            "Invalid limit value provided. Minimum limit is 1",
        )),
        _ => Err(serde::de::Error::custom(
            "Invalid limit value provided. Maximum limit is 1000",
        )),
    }
}

/// This function provides the default sleep duration in milliseconds.
/// It is used as the default value for deserialization of the `sleep_duration` field,
/// of `OktaConfig` in the event that no value is provided.
fn default_sleep_milliseconds() -> u64 {
    1000
}

fn default_canon_time() -> u64 {
    60
}

/// This function provides the default limit for the number of system logs returned from Okta.
/// It is used as the default value for deserialization of the `limit` field,
/// of `OktaConfig` in the event that no value is provided.
fn default_okta_limit() -> u16 {
    100
}

/// This function provides the default log sorting direction.
/// It is used as the default value for deserialization of the `log_sorting` field,
/// of `OktaConfig` in the event that no value is provided.
fn default_log_sorting() -> String {
    "ASCENDING".to_string()
}

pub struct Okta {
    /// A `reqwest` client to send API calls with
    client: Client,
    /// Contains domain and token
    config: OktaConfig,
    /// Timestamp of the last seen log we have processed
    last_seen: OffsetDateTime,
    /// Sending channel used to send logs into the execution system
    logger: Sender<Message>,
    /// An LRU where we store the UUIDs of Okta logs that we have already seen and sent into the logging system.
    /// This, together with some overlapping queries to the Okta API, helps us ensure that all Okta logs are processed
    /// exactly once.
    /// This LRU has a limited capacity: when this is reached, the least-recently-used item is removed to make space for a new insertion.
    /// Note: we only use the "key" part to keep track of the UUIDs we have seen. The "value" part is not used and always set to 0u32.
    seen_logs_uuid: LruCache<String, u32>,
}

impl Okta {
    pub fn new(config: OktaConfig, logger: Sender<Message>) -> Self {
        let client = reqwest::Client::builder()
            .timeout(Duration::from_secs(5))
            .build()
            .unwrap();

        Self {
            client,
            config,
            last_seen: OffsetDateTime::now_utc(),
            logger,
            seen_logs_uuid: LruCache::new(NonZeroUsize::new(4096).unwrap()),
        }
    }
}

impl DataGenerator for &mut Okta {
    // For the documentation on these methods, see the trait.

    async fn fetch_logs(
        &self,
        since: OffsetDateTime,
        until: OffsetDateTime,
    ) -> Result<Vec<super::DataGeneratorLog>, ()> {
        // Okta requires the query parameters to be in RFC3339 format. We attempt to format them here.
        // On failure, we return and allow the data orchestrator to restart the loop
        let since = match since.format(&Rfc3339) {
            Ok(since) => since,
            Err(e) => {
                error!("Failed to parse 'since' datetime to RFC3339 format. Error: {e}");
                return Err(());
            }
        };
        let until = match until.format(&Rfc3339) {
            Ok(until) => until,
            Err(e) => {
                error!("Failed to parse 'until' datetime to RFC3339 format. Error: {e}");
                return Err(());
            }
        };

        // TODO Maybe remove configurability for sortOrder. With this new system, only ASCENDING
        // really makes sense. Otherwise we are most likely going to miss older logs.
        let address = format!(
            "https://{}/api/v1/logs?sortOrder={}&since={since}&until={until}&limit={}",
            self.config.domain, self.config.log_sorting, self.config.limit
        );

        let response = self
            .client
            .get(address)
            .header("Accept", "application/json")
            .header("Authorization", format!("SSWS {}", self.config.token))
            .send()
            .await
            .map_err(|e| {
                error!("Could not get logs from Okta: {e}");
            })?;

        // Check the response status code
        // If it's outside of the 2XX range, we log the error and exit the loop, allowing the
        // data generator to handle a restart
        if !response.status().is_success() {
            let status = response.status();
            let error_body = response.text().await.ok();
            error!(
                "Call to Okta API failed with code: {status}. Error: {}",
                error_body.unwrap_or_default()
            );
            return Err(());
        }

        // Get the body from the response from Okta
        let body = response
            .text()
            .await
            .map_err(|e| error!("Could not get logs from Okta: {e}"))?;

        // Attempt to deserialize the response from Okta
        let logs: Vec<Value> = serde_json::from_str(body.as_str())
            .map_err(|e| error!("Could not parse data from Okta: {e}"))?;

        // If there have been no new logs since we last polled, we can exit the loop early
        // Exiting here will result in a 10 second wait between restarts
        if logs.is_empty() {
            debug!("No new Okta logs since: {}", self.last_seen);
            return Ok(vec![]);
        }

        // Loop over the logs we did get from Okta, attempt to parse their timestamps, and return a vector of such logs
        let mut output_logs: Vec<DataGeneratorLog> = Vec::with_capacity(logs.len());

        for log in &logs {
            let published = match log
                .as_object()
                .and_then(|obj| obj.get(OKTA_LOG_PUBLISHED_FIELD_KEY))
                .and_then(|val| val.as_str())
            {
                Some(published) => published,
                None => {
                    error!("Missing or invalid 'published' field in Okta log",);
                    continue;
                }
            };

            let log_timestamp = match OffsetDateTime::parse(published, &Rfc3339) {
                Ok(dt) => dt,
                Err(_) => {
                    error!("Got an invalid date from Okta: {}", published);
                    continue;
                }
            };

            let uuid = match log
                .as_object()
                .and_then(|obj| obj.get(OKTA_LOG_UUID_FIELD_KEY))
                .and_then(|val| val.as_str())
            {
                Some(uuid) => uuid,
                None => {
                    error!("Missing or invalid 'uuid' field in Okta log",);
                    continue;
                }
            };

            // Attempt to parse the log received from Okta to bytes.
            let log_bytes = match serde_json::to_vec(&log) {
                Ok(bytes) => bytes,
                Err(e) => {
                    error!("Failed to serialize Okta logs to bytes. Error: {e}");
                    continue;
                }
            };

            output_logs.push(DataGeneratorLog {
                id: uuid.to_string(),
                timestamp: log_timestamp,
                payload: log_bytes,
            });
        }

        Ok(output_logs)
    }

    fn get_name(&self) -> String {
        "Okta".to_string()
    }

    fn get_sleep_duration(&self) -> u64 {
        self.config.sleep_duration
    }

    fn get_canon_time(&self) -> u64 {
        self.config.canon_time
    }

    fn get_last_seen(&self) -> OffsetDateTime {
        self.last_seen
    }

    fn set_last_seen(&mut self, v: OffsetDateTime) {
        self.last_seen = v;
    }

    fn was_already_seen(&self, id: impl std::fmt::Display) -> bool {
        self.seen_logs_uuid.contains(&id.to_string())
    }

    fn mark_already_seen(&mut self, id: impl std::fmt::Display) {
        self.seen_logs_uuid.put(id.to_string(), 0u32);
    }

    fn send_for_processing(&self, payload: Vec<u8>) {
        self.logger
            .send(Message::new(
                "okta".to_string(),
                payload,
                LogSource::Generator(Generator::Okta),
                self.config.logbacks_allowed.clone(),
            ))
            .unwrap();
    }
}
