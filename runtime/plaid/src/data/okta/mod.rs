use crate::{data::DataGeneratorLog, executor::Message};
use crossbeam_channel::Sender;
use lru::LruCache;
use plaid_stl::messages::{Generator, LogSource, LogbacksAllowed};
use reqwest::Client;
use serde::Deserialize;
use serde_json::Value;
use std::{num::NonZeroUsize, time::Duration};
use time::{format_description::well_known::Rfc3339, OffsetDateTime};

use super::DataGenerator;

const OKTA_LOG_PUBLISHED_FIELD_KEY: &str = "published";
const OKTA_LOG_UUID_FIELD_KEY: &str = "uuid";

#[derive(Deserialize)]
pub struct OktaConfig {
    /// API token used to authenticate to Okta
    token: String,
    /// Domain that API calls will be sent to
    domain: String,
    /// Sets the number of results that are returned in the response
    /// If no value is provided here, we will default to 100.
    #[serde(deserialize_with = "parse_limit")]
    #[serde(default = "default_okta_limit")]
    limit: u16,
    /// Number of milliseconds to wait in between calls to the Okta API.
    /// Okta enforces a rate limit of 50 calls/sec for the `/logs` endpoint.
    #[serde(default = "default_sleep_milliseconds")]
    sleep_duration: u64,
    /// The maximum number of logbacks that each rule will be allowed to trigger
    /// per message received. If this is set to Limited(0), no rule will be able to use the log
    /// back functionality from messages generated by this webhook. If this is set to Limited(1),
    /// then EACH RULE will be able to trigger one logback. If this is set to Unlimited, then
    /// each rule will be able to trigger as many logbacks as they want (and those triggered rules
    /// will be able to as well). If this is not set, it will default to Limited(0).
    #[serde(default)]
    pub logbacks_allowed: LogbacksAllowed,
    /// Canonicalization time, i.e., after how many seconds we can consider logs as "stable"
    #[serde(default = "default_canon_time")]
    canon_time: u64,
    /// Size of the LRU cache that we use to deduplicate logs
    #[serde(default = "default_lru_cache_size")]
    lru_cache_size: usize,
    /// Max number of seconds in the since..until span for pulling logs from the source
    #[serde(default = "default_since_until")]
    max_since_until: u64,
    /// Max number of seconds for the look-back window
    #[serde(default = "default_max_catchup")]
    max_catchup: u64,
}

/// Custom parser for limit. Returns an error if a limit = 0 or limit > 1000 is given
fn parse_limit<'de, D>(deserializer: D) -> Result<u16, D::Error>
where
    D: serde::Deserializer<'de>,
{
    let limit = u16::deserialize(deserializer)?;

    match limit {
        1..=1000 => Ok(limit),
        0 => Err(serde::de::Error::custom(
            "Invalid limit value provided. Minimum limit is 1",
        )),
        _ => Err(serde::de::Error::custom(
            "Invalid limit value provided. Maximum limit is 1000",
        )),
    }
}

/// This function provides the default sleep duration in milliseconds.
/// It is used as the default value for deserialization of the `sleep_duration` field,
/// of `OktaConfig` in the event that no value is provided.
fn default_sleep_milliseconds() -> u64 {
    1000
}

/// This function provides the default max value for the since..until time span, in seconds.
/// It is used as the default value for deserialization of the `max_since_until` field,
/// of `OktaConfig` in the event that no value is provided.
fn default_since_until() -> u64 {
    60
}

/// This function provides the default max value for the max catch-up look-back window.
fn default_max_catchup() -> u64 {
    3 * 3600 // 3 hours
}

/// This function provides the default size of the LRU cache.
fn default_lru_cache_size() -> usize {
    4096
}

fn default_canon_time() -> u64 {
    60
}

/// This function provides the default limit for the number of system logs returned from Okta.
/// It is used as the default value for deserialization of the `limit` field,
/// of `OktaConfig` in the event that no value is provided.
fn default_okta_limit() -> u16 {
    1000
}

pub struct Okta {
    /// A `reqwest` client to send API calls with
    client: Client,
    /// Contains domain and token
    config: OktaConfig,
    /// Timestamp of the last seen log we have processed
    last_seen: OffsetDateTime,
    /// Sending channel used to send logs into the execution system
    logger: Sender<Message>,
    /// An LRU where we store the UUIDs of Okta logs that we have already seen and sent into the logging system.
    /// This, together with some overlapping queries to the Okta API, helps us ensure that all Okta logs are processed
    /// exactly once.
    /// This LRU has a limited capacity: when this is reached, the least-recently-used item is removed to make space for a new insertion.
    /// Note: we only use the "key" part to keep track of the UUIDs we have seen. The "value" part is not used and always set to 0u32.
    seen_logs_uuid: LruCache<String, u32>,
}

impl Okta {
    pub fn new(config: OktaConfig, logger: Sender<Message>) -> Self {
        let client = reqwest::Client::builder()
            .timeout(Duration::from_secs(5))
            .build()
            .unwrap();
        let lru_cache_size = config.lru_cache_size;

        Self {
            client,
            config,
            last_seen: OffsetDateTime::now_utc(),
            logger,
            seen_logs_uuid: LruCache::new(NonZeroUsize::new(lru_cache_size).unwrap()),
        }
    }
}

impl DataGenerator for Okta {
    // For the documentation on these methods, see the trait.

    async fn fetch_logs(
        &self,
        since: OffsetDateTime,
        until: OffsetDateTime,
    ) -> Result<Vec<super::DataGeneratorLog>, ()> {
        // Okta requires the query parameters to be in RFC3339 format. We attempt to format them here.
        // On failure, we return and allow the data orchestrator to restart the loop
        let since = match since.format(&Rfc3339) {
            Ok(since) => since,
            Err(e) => {
                error!("Failed to parse 'since' datetime to RFC3339 format. Error: {e}");
                return Err(());
            }
        };
        let until = match until.format(&Rfc3339) {
            Ok(until) => until,
            Err(e) => {
                error!("Failed to parse 'until' datetime to RFC3339 format. Error: {e}");
                return Err(());
            }
        };

        let address = format!(
            "https://{}/api/v1/logs?sortOrder=ASCENDING&since={since}&until={until}&limit={}",
            self.config.domain, self.config.limit
        );

        let mut output_logs = vec![];
        let mut next = Some(address);

        loop {
            // At this point we know `next` is Some. Either because this is the first request, or
            // because we are here after checking it's not None (which would have stopped the loop).
            let response = self
                .client
                .get(next.unwrap())
                .header("Accept", "application/json")
                .header("Authorization", format!("SSWS {}", self.config.token))
                .send()
                .await
                .map_err(|e| {
                    error!("Could not get logs from Okta: {e}");
                })?;

            // Check the response status code
            // If it's outside of the 2XX range, we log the error and exit the loop, allowing the
            // data generator to handle a restart
            if !response.status().is_success() {
                let status = response.status();
                let error_body = response.text().await.ok();
                error!(
                    "Call to Okta API failed with code: {status}. Error: {}",
                    error_body.unwrap_or_default()
                );
                return Err(());
            }

            // See if there is another page of logs after this by looking at the `link` header
            // https://developer.okta.com/docs/api/#link-header
            next = response
                .headers()
                .get("link")
                .and_then(|v| super::get_next_from_link_header(v));

            // Get the body from the response from Okta
            let body = response
                .text()
                .await
                .map_err(|e| error!("Could not get logs from Okta: {e}"))?;

            // Attempt to deserialize the response from Okta
            let logs: Vec<Value> = serde_json::from_str(body.as_str())
                .map_err(|e| error!("Could not parse data from Okta: {e}"))?;

            if logs.is_empty() {
                return Ok(output_logs);
            }

            // Loop over the logs we got from Okta, parse them and add them to the growing vector
            for log in &logs {
                let published = match log
                    .as_object()
                    .and_then(|obj| obj.get(OKTA_LOG_PUBLISHED_FIELD_KEY))
                    .and_then(|val| val.as_str())
                {
                    Some(published) => published,
                    None => {
                        error!("Missing or invalid 'published' field in Okta log",);
                        continue;
                    }
                };

                let log_timestamp = match OffsetDateTime::parse(published, &Rfc3339) {
                    Ok(dt) => dt,
                    Err(_) => {
                        error!("Got an invalid date from Okta: {}", published);
                        continue;
                    }
                };

                let uuid = match log
                    .as_object()
                    .and_then(|obj| obj.get(OKTA_LOG_UUID_FIELD_KEY))
                    .and_then(|val| val.as_str())
                {
                    Some(uuid) => uuid,
                    None => {
                        error!("Missing or invalid 'uuid' field in Okta log",);
                        continue;
                    }
                };

                // Attempt to parse the log received from Okta to bytes.
                let log_bytes = match serde_json::to_vec(&log) {
                    Ok(bytes) => bytes,
                    Err(e) => {
                        error!("Failed to serialize Okta logs to bytes. Error: {e}");
                        continue;
                    }
                };

                output_logs.push(DataGeneratorLog {
                    id: uuid.to_string(),
                    timestamp: log_timestamp,
                    payload: log_bytes,
                });
            }

            // Exit the loop if there is no next page
            if next.is_none() {
                break;
            }
            // Otherwise we are ready for the next request
        }

        Ok(output_logs)
    }

    fn get_name(&self) -> String {
        "Okta".to_string()
    }

    fn get_sleep_duration(&self) -> u64 {
        self.config.sleep_duration
    }

    fn get_canon_time(&self) -> u64 {
        self.config.canon_time
    }

    fn get_last_seen(&self) -> OffsetDateTime {
        self.last_seen
    }

    fn set_last_seen(&mut self, v: OffsetDateTime) {
        self.last_seen = v;
    }

    fn was_already_seen(&self, id: impl std::fmt::Display) -> bool {
        self.seen_logs_uuid.contains(&id.to_string())
    }

    fn mark_already_seen(&mut self, id: impl std::fmt::Display) {
        self.seen_logs_uuid.put(id.to_string(), 0u32);
    }

    fn send_for_processing(&self, payload: Vec<u8>) -> Result<(), ()> {
        self.logger
            .send(Message::new(
                "okta".to_string(),
                payload,
                LogSource::Generator(Generator::Okta),
                self.config.logbacks_allowed.clone(),
            ))
            .map_err(|_| ())
    }

    fn list_already_seen(&self) -> Vec<String> {
        self.seen_logs_uuid
            .iter()
            .map(|(key, _val)| key.to_string())
            .collect()
    }

    fn get_max_since_until_interval(&self) -> u64 {
        self.config.max_since_until
    }

    fn get_max_catchup_time(&self) -> u64 {
        self.config.max_catchup
    }
}
